# Cours sur le parallÃ¨lisme (Master ILSEN)

## Aide mÃ©moire pour mon Ã©valuation



Imagine un **restaurant** :

- Le **processus**, câ€™est **tout le restaurant** : la cuisine, les serveurs, les plats, les clientsâ€¦
- Les **threads**, ce sont les **serveurs** : ils font tous partie du mÃªme resto, partagent les mÃªmes plats, mais chacun peut aller **servir une table diffÃ©rente en mÃªme temps**





#### Notion de processus

#### ğŸŒ± DÃ©finition

Un **processus**, câ€™est **un programme en cours dâ€™exÃ©cution**.

Par exemple, quand tu lances Firefox ou ton terminal, chacun devient un processus.

#### ğŸ“¦ CaractÃ©ristiques dâ€™un processus

- **IsolÃ© des autres** :
  - En **temps** â†’ comme sâ€™il avait son propre CPU.
  - En **espace mÃ©moire** â†’ il ne voit pas les donnÃ©es des autres processus.

#### ğŸ“‘ Il possÃ¨de :

- Un **PID** (Process ID).
- Un **contexte mÃ©moire** :
  - `.text` = instructions du programme.
  - `.data` = variables globales.
  - `.heap` = mÃ©moire allouÃ©e dynamiquement (via `new`).
  - `.stack` = pile dâ€™exÃ©cution (appels de fonctions, variables locales, etc.).



#### Notion de thread

#### ğŸŒ± DÃ©finition

Un **thread**, câ€™est une tÃ¢che **lÃ©gÃ¨re** Ã  lâ€™intÃ©rieur dâ€™un processus. Câ€™est comme un **sous-programme** qui peut sâ€™exÃ©cuter en **parallÃ¨le** avec les autres. Un **thread** est un **petit programme** Ã  lâ€™intÃ©rieur dâ€™un **gros programme (le processus)**. Câ€™est comme une **fonction** qui tourne **en parallÃ¨le** avec dâ€™autres.

#### ğŸ¯ Pourquoi utiliser des threads ?

- Pour **utiliser plusieurs cÅ“urs** du CPU en mÃªme temps.
- Pour Ã©crire du code **plus rapide et rÃ©actif** (ex. : interface graphique + calculs en fond).

#### ğŸ§  CaractÃ©ristiques

- **Partage la mÃ©moire** avec les autres threads du mÃªme processus.
- Chaque thread a sa **propre pile (stack)** pour ses variables locales.
- Ils peuvent sâ€™exÃ©cuter indÃ©pendamment.



exemple de base

```cpp
#include <iostream>
#include <thread>

void direBonjour() {
    std::cout << "Bonjour depuis un thread !" << std::endl;
}

int main() {
    std::thread t1(direBonjour); // CrÃ©ation du thread
    t1.join(); // On attend que le thread se termine
    return 0;
}

```

ğŸ§¾ Ce que fait ce code :

- Il crÃ©e un thread qui exÃ©cute la fonction `direBonjour()`.
- `join()` permet de dire : "attend que le thread ait fini avant de quitter le programme."



##### ğŸ§  La **pile**, le **tas**, les **variables globales**

###### ğŸ“¦ 1. La **pile (stack)**

Câ€™est lÃ  oÃ¹ sont stockÃ©es :

- Les **variables locales** Ã  une fonction
- Les **arguments** de fonction
- Le **chemin dâ€™exÃ©cution** (pour savoir oÃ¹ on est)

ğŸ“Œ Chaque **thread a sa propre pile**. Donc les variables locales ne se mÃ©langent pas !



###### ğŸ—ƒï¸ 2. Le **tas (heap)**

Câ€™est la **mÃ©moire dynamique**. Par exemple quand tu fais :

```
int* p = new int(5);
```

â›² LÃ , tu demandes un **int** sur le tas (heap), et tous les threads peuvent y accÃ©der sâ€™ils partagent le pointeur.

ğŸ“Œ Le **tas est partagÃ©** entre les threads : donc attention aux conflits !



###### ğŸŒ 3. Les **variables globales**

Elles sont partagÃ©es **par tous les threads**.

```
int compteur = 0;

void incrementer() {
    compteur++;
}
```

ğŸ“Œ Si plusieurs threads modifient `compteur` **en mÃªme temps**, il y a des **problÃ¨mes** â†’ câ€™est ce quâ€™on appelle une **condition de course (race condition)** ğŸ˜±



##### âš™ï¸ Utiliser plusieurs **cÅ“urs CPU** grÃ¢ce aux threads

Quand tu crÃ©es plusieurs threads, le systÃ¨me dâ€™exploitation peut les faire tourner :

- Soit sur le **mÃªme cÅ“ur**, un par un (tour par tour)
- Soit sur **des cÅ“urs diffÃ©rents en parallÃ¨le**, si ton CPU en a plusieurs

### â¤ Exemple :

Si tu as un **CPU Ã  4 cÅ“urs**, tu peux lancer 4 threads qui sâ€™exÃ©cutent **vraiment en mÃªme temps** ğŸ§ ğŸ§ .

ğŸ§ª Exemple C++11 avec plusieurs threads :



```cpp
#include <iostream>
#include <thread>

void travail(int id) {
    std::cout << "Thread " << id << " travaille...\n";
}

int main() {
    std::thread t1(travail, 1);
    std::thread t2(travail, 2);

    t1.join();
    t2.join();

    return 0;
}

```

##### ğŸ“ Bonnes pratiques pour dÃ©buter

 âœ… Utilise des **fonctions simples** dans chaque thread
 âœ… Fais attention au **partage de mÃ©moire** (tas et variables globales)
 âœ… Utilise des **verrous (mutex)** quand plusieurs threads Ã©crivent dans la mÃªme donnÃ©e
 âœ… **Toujours appeler `.join()`** pour attendre la fin du thread (sinon bug !)

#### Processus lourd VS lÃ©ger

|                            | **Processus (lourd)** | **Thread (lÃ©ger)**      |
| -------------------------- | --------------------- | ----------------------- |
| **MÃ©moire**                | SÃ©parÃ©e               | PartagÃ©e                |
| **Pile**                   | SÃ©parÃ©e               | SÃ©parÃ©e                 |
| **Registres CPU**          | SÃ©parÃ©s               | SÃ©parÃ©s                 |
| **Fichiers ouverts**       | Propres               | PartagÃ©s                |
| **Changement de contexte** | Lent                  | Rapide                  |
| **Communication**          | Difficile             | Facile (par la mÃ©moire) |

Processus : chacun avec sa mÃ©moire
Threads : partagent le tas et les variables globales



##### **Partage de mÃ©moire entre threads**

###### ğŸ“¦ Les threads partagent :

- Les **variables globales** (`int compteur`).
- Le **tas** (`new`, `malloc`).

###### ğŸ§‘â€ğŸ¤â€ğŸ§‘ Chaque thread a :

- Sa **propre pile (stack)** avec ses variables locales et registres.



```mathematica
MÃ©moire PartagÃ©e (tas, globales)
â”œâ”€â”€ Thread A : sa propre pile
â”œâ”€â”€ Thread B : sa propre pile
â”œâ”€â”€ Thread C : sa propre pile
```



exemple

```cpp
#include <iostream>
#include <thread>
using namespace std;

int compteur = 0;

void f() {
    compteur += 1;
}

int main() {
    thread t1(f);
    thread t2(f);
    t1.join();
    t2.join();
    cout << "Compteur = " << compteur << endl;
    return 0;
}
```

â¡ï¸ Ici, `compteur` est **partagÃ©** par les deux threads. Ils peuvent lâ€™**Ã©craser** si on ne protÃ¨ge pas son accÃ¨s (avec un mutex par exemple, mais Ã§a vient aprÃ¨s dans le cours).



Tu peux aussi crÃ©er un thread **sans tÃ¢che**, et lui en attribuer une plus tard :

```cpp
thread u;
u = thread(g, 20);
u.join();
```



#### Operator()

âœ… Ã€ quoi Ã§a sert ?

En C++11, quand tu veux crÃ©er un `std::thread`, tu peux lui donner :

- une **fonction**
- un **lambda**
- ouâ€¦ un **objet qui se comporte comme une fonction** â†’ **grÃ¢ce Ã  `operator()`**

Exemple

```cpp
#include <iostream>
#include <thread>
using namespace std;

class W {
public:
    void operator()() {
        cout << "OpÃ©rateur () appelÃ©" << endl;
    }
};

int main() {
    W zz;             // zz est un objet de type W
    thread t(zz);     // on passe zz au thread -> comme une fonction !
    t.join();         // on attend que le thread se termine
    return 0;
}
```

### Ce quâ€™il se passe :

1. Tu crÃ©es un objet `zz` de type `W`.
2. Tu dis : `thread t(zz);`
   - Le thread regarde : "Est-ce que `zz` est **appelable** comme une fonction ?"
   - Oui ! Parce quâ€™il a `operator()`.
3. Le thread **exÃ©cute le contenu** de `operator()()` dans un thread sÃ©parÃ©.

ğŸ’¡ Câ€™est comme si tu faisais :

```cpp
void f() {
    cout << "Fonction appelÃ©e" << endl;
}

thread t(f); // mÃªme idÃ©e
```

Mais lÃ , tu utilises une **classe personnalisÃ©e qui se comporte comme une fonction**.



######  ğŸ“ Pourquoi utiliser Ã§a ?

- Tu peux **garder des variables dans la classe** si tu veux quâ€™un thread ait un **Ã©tat**.
- TrÃ¨s pratique si tu veux crÃ©er des **tÃ¢ches personnalisÃ©es et rÃ©utilisables**.

exemple



```cpp
class Compteur {
    int debut, fin;
public:
    Compteur(int d, int f) : debut(d), fin(f) {}

    void operator()() {
        for (int i = debut; i <= fin; ++i)
            cout << i << " ";
        cout << endl;
    }
};

int main() {
    Compteur c(1, 5); // Compteur de 1 Ã  5
    thread t(c);      // Lancement dans un thread
    t.join();
    return 0;
}

ğŸ” RÃ©sultat :
1 2 3 4 5
```

ğŸ’¡ Ici, tu vois quâ€™on peut **passer des donnÃ©es** Ã  notre objet (`debut`, `fin`) et les utiliser dans `operator()`.

| Ã‰lÃ©ment         | Signification                                              |
| --------------- | ---------------------------------------------------------- |
| `operator()()`  | Permet Ã  une classe de se **comporter comme une fonction** |
| `thread t(zz);` | CrÃ©e un thread en lanÃ§ant `zz.operator()()`                |
| Avantage        | Tu peux garder des **donnÃ©es internes** dans la classe     |



#### ParallÃ¨lisme avec 2 threads



exemple



```cpp
vector<int> a = {1, 3, 5, 8};
vector<int> b = {7, 3, 3, -4};
vector<int> c(4);

void add(int start, int end) {
    for (int i = start; i < end; i++) {
        c[i] = a[i] + b[i];
    }
}

int main() {
    thread t1(add, 0, 2); // traite indices 0 et 1
    thread t2(add, 2, 4); // traite indices 2 et 3
    t1.join();
    t2.join();
    return 0;
}

```



ğŸ“Œ Attention : ici les threads partagent `c`, donc si plusieurs threads Ã©crivent au **mÃªme endroit**, il faut **protÃ©ger** la mÃ©moire (mutex, atomicâ€¦ quâ€™on verra plus tard).



#### Les fonctions **lambda** avec threads

Une **lambda** câ€™est une **fonction anonyme** (sans nom) que tu dÃ©finis **Ã  la volÃ©e**.



exemple simple

```cpp
auto action = []() {
    cout << "Thread avec lambda" << endl;
};

thread t(action);
t.join();
```



exemple fonction lambda avec paramÃ¨tres

```cpp
auto action = [](int x, int y) {
    cout << "Somme = " << x + y << endl;
};

thread t(action, 3, 4); // Affiche Somme = 7
t.join();
```



exemple avec capture de vairiables

```cpp
int x = 2, y = 3;
auto action = [x, y]() {
    cout << "Produit = " << x * y << endl;
};
thread t(action);
t.join();
```



exemple avec capture par rÃ©fÃ©rence (modifie la vraie variable)

```cpp
int somme = 0;
auto action = [&somme]() {
    for (int i = 0; i < 5; i++) somme += i;
};
thread t(action);
t.join();
cout << "Somme = " << somme << endl; // Somme = 10
```



exemple lambda dans une classe

```cpp
class Toto {
private:
    int somme = 0;

public:
    void fonction() {
        auto action = [this]() {
            for (int i = 0; i < 10; i++) somme += i;
        };
        thread t(action);
        t.join();
    }
};
```





#### detach()

ğŸ’¥ `detach` : le thread continue **en arriÃ¨re-plan** tout seul.



```cpp
void f() {
    cout << "Je suis dÃ©tachÃ©..." << endl;
}

int main() {
    thread t(f);
    t.detach(); // Le thread devient indÃ©pendant
}
```

ğŸ§  Mais attention ! Si ton programme principal **finit trop vite**, le thread dÃ©tachÃ© **nâ€™aura pas le temps de sâ€™exÃ©cuter** !



#### sleep_for

 Faire une pause

```cpp
#include <chrono>
#include <thread>

this_thread::sleep_for(chrono::seconds(3)); // Attend 3 secondes
```



Exemple avec lambda et pause

```cpp
for (int i = 0; i < 5; i++) {
    thread t([i] {
        if (i == 0)
            this_thread::sleep_for(chrono::seconds(5));
        cout << "Thread #" << i << endl;
    });
    t.join(); // Important sinon le thread sera tuÃ© tout de suite
}
```




#### Synchronisation



### ğŸ’£ Pourquoi ?

Tous les threads partagent la mÃªme mÃ©moire â†’ ils peuvent **Ã©craser** les donnÃ©es.



ğŸ§¤ `mutex` (verrou) 

exemple 

```cpp
#include <mutex>

mutex m;
int compteur = 0;

void increment() {
    for (int i = 0; i < 1000; i++) {
        m.lock();
        compteur++;
        m.unlock();
    }
}
```

âš ï¸ Si tu oublies le `unlock()`, Ã§a peut **bloquer Ã  jamais** d'autres threads.





âœ… `lock_guard` (verrou automatique)

exemple 

```cpp
void increment() {
    for (int i = 0; i < 1000; i++) {
        lock_guard<mutex> verrou(m);
        compteur++;
    }
}
```

â¡ï¸ **Plus sÃ»r**, car le mutex est libÃ©rÃ© **automatiquement** Ã  la fin du bloc `{}`.



ğŸ’ `atomic`

exemple

```cpp
#include <atomic>

atomic<int> compteur(0);

void increment() {
    for (int i = 0; i < 1000; i++) {
        compteur++;
    }
}
```

â¡ï¸ **Pas besoin de mutex !** Mais Ã§a ne marche que pour des types simples (`int`, `bool`, etc.).





#### ProblÃ¨mes classiques rencontrÃ©s



ğŸŒ€ **Race Condition**

Deux threads Ã©crivent en **mÃªme temps** â†’ rÃ©sultat **imprÃ©visible**.

```cpp
int total = 500;

void add(int x) {
    total += x;
}

int main() {
    thread t1(add, 50);
    thread t2(add, 50);
    t1.join();
    t2.join();
    cout << "Total = " << total << endl;
}
```

ğŸ’¥ RÃ©sultat : parfois 600, parfois 550, etc. => il faut un `mutex` pour protÃ©ger.



ğŸ§¨ **Deadlock**

Deux threads attendent **mutuellement** une ressource => **blocage total**.

```cpp
mutex m1, m2;

void t1() {
    m1.lock();
    m2.lock();
    // travail
    m2.unlock();
    m1.unlock();
}

void t2() {
    m2.lock();
    m1.lock();
    // travail
    m1.unlock();
    m2.unlock();
}
```

â¡ï¸ Solution : toujours **verrouiller dans le mÃªme ordre**.

## ğŸ§¨ Deadlock : câ€™est quoi exactement ?

Imagine deux **personnes** qui veulent chacune utiliser **deux fourchettes** pour manger ğŸ´ğŸ´.

- **Personne A** prend la **fourchette 1** et attend la **fourchette 2**.
- **Personne B** prend la **fourchette 2** et attend la **fourchette 1**.

ğŸ’¥ RÃ©sultat : **elles se bloquent Ã  jamais**. Personne ne lÃ¢che sa fourchette. Personne ne peut manger. => **Deadlock** (blocage total).

## ğŸ§  En programmation, câ€™est pareil :

Tu as deux **threads** (tÃ¢ches en parallÃ¨le), et deux **ressources** protÃ©gÃ©es par des **verrous** (`mutex`).

### ğŸ” Les `mutex`

- Ce sont des **verrous**, pour Ã©viter que deux threads Ã©crivent en mÃªme temps dans une mÃªme mÃ©moire.
- `lock()` => je verrouille
- `unlock()` => je dÃ©verrouille

exemple de blockage avec deadlock

```cpp
#include <iostream>
#include <thread>
#include <mutex>
using namespace std;

mutex m1, m2;

void t1() {
    m1.lock();          // ğŸ”’ thread t1 verrouille m1
    this_thread::sleep_for(chrono::milliseconds(100));
    m2.lock();          // ğŸ§¨ attend m2 qui est peut-Ãªtre dÃ©jÃ  pris !
    cout << "t1 travaille" << endl;
    m2.unlock();
    m1.unlock();
}

void t2() {
    m2.lock();          // ğŸ”’ thread t2 verrouille m2
    this_thread::sleep_for(chrono::milliseconds(100));
    m1.lock();          // ğŸ§¨ attend m1 qui est peut-Ãªtre dÃ©jÃ  pris !
    cout << "t2 travaille" << endl;
    m1.unlock();
    m2.unlock();
}

int main() {
    thread a(t1);
    thread b(t2);
    a.join();
    b.join();
    return 0;
}
```

ğŸ§¨ Ce quâ€™il se passe ici :

| Temps | Thread t1            | Thread t2            |
| ----- | -------------------- | -------------------- |
| 0 ms  | `m1.lock()`          | `m2.lock()`          |
| 100ms | essaie `m2.lock()` âŒ | essaie `m1.lock()` âŒ |

ğŸ” Les deux attendent indÃ©finiment = **DEADLOCK**.



âœ… Solution : verrouiller dans **le mÃªme ordre**

Au lieu de :

```cpp
t1 â†’ m1 puis m2  
t2 â†’ m2 puis m1 âŒ (ordre diffÃ©rent !)
```

On **force** les deux threads Ã  toujours faire dans le mÃªme ordre, par exemple :

```cpp
void t1() {
    m1.lock();
    m2.lock();
    // ...
    m2.unlock();
    m1.unlock();
}

void t2() {
    m1.lock();  // ğŸ‘ˆ mÃªme ordre que t1
    m2.lock();
    // ...
    m2.unlock();
    m1.unlock();
}
```

ğŸ’¡ RÃ©sultat : pas de deadlock car personne ne reste bloquÃ© en attendant quelque chose que l'autre possÃ¨de **dans un ordre inverse**.



ğŸ§ª Encore mieux : utiliser `std::lock`

En C++11, tu peux faire :

```cpp
std::lock(m1, m2);
```

Cela verrouille **plusieurs mutex en toute sÃ©curitÃ©**, sans deadlock possible.

ğŸ”’ Exemple sÃ»r avec `std::lock`

```cpp
void t1() {
    std::lock(m1, m2);
    lock_guard<mutex> lg1(m1, std::adopt_lock);
    lock_guard<mutex> lg2(m2, std::adopt_lock);
    // travail
}
```

âœ… `std::adopt_lock` dit : â€œles mutex sont dÃ©jÃ  verrouillÃ©s, pas besoin de les verrouiller encore.â€





#### ğŸ§â€â™‚ï¸ **Starvation**

Un thread **attend trop longtemps** une ressource que les autres accaparent.

Pas dâ€™exemple direct ici, mais Ã§a peut arriver si on priorise toujours les mÃªmes threads.





### Patrons de conception



#### ğŸª“ 1. **Fork-Join**

- **Fork** : le programme se divise en plusieurs threads.
- **Join** : on attend que les threads aient fini avant de continuer.

exemple

```cpp
void travail(int i) {
    cout << "Thread " << i << " travaille" << endl;
}

int main() {
    thread t1(travail, 1);
    thread t2(travail, 2);
    t1.join();
    t2.join();
    cout << "Tous les threads ont terminÃ©" << endl;
}
```



#### ğŸ‘‘ 2. **MaÃ®tre-Esclave**

- Un thread **maÃ®tre** donne du travail aux **esclaves** (workers).
- Il gÃ¨re la coordination.



#### â˜ï¸ 3. **Client-Serveur**

- Le **serveur** rÃ©pond Ã  des requÃªtes venant de plusieurs **clients**.



#### ğŸš° 4. **Pipeline**

- Une tÃ¢che est dÃ©coupÃ©e en **Ã©tapes successives**.
- Chaque thread fait **une Ã©tape**, puis passe Ã  la suivante.

Exemple imagÃ© :

> Thread A fait "lire", Thread B fait "traiter", Thread C fait "enregistrer".



#### ğŸ§º 5. **Bassin de tÃ¢ches / Producteur-Consommateur**

- **Thread Pool** : plusieurs threads prÃªts Ã  exÃ©cuter des tÃ¢ches dÃ¨s quâ€™elles sont disponibles.
- **Producteur-Consommateur** :
  - Le producteur met des donnÃ©es dans un **tampon**.
  - Le consommateur lit les donnÃ©es du tampon.



### Performance & Speedup



## ğŸï¸ 1. **Pourquoi mesurer les performances ?**

Quand tu Ã©cris un programme **parallÃ¨le** (avec plusieurs threads, plusieurs cÅ“urs...), lâ€™idÃ©e, câ€™est de le faire **plus rapide** que le mÃªme programme en version **sÃ©quentielle** (ligne par ligne, un seul cÅ“ur CPU).

Mais... **est-ce que Ã§a vaut le coup ?** ğŸ¤”
 On a besoin dâ€™un moyen pour **mesurer** le gain de vitesse. Câ€™est lÃ  quâ€™arrive la notion de **speedup** !



ğŸ“Š 2. **Quâ€™est-ce que le Speedup ?**



ğŸ”¢ Formule :



```cpp
Sp = Tseq / Tp
```

- `Tseq` = Temps dâ€™exÃ©cution en **sÃ©quentiel** (sur 1 cÅ“ur)
- `Tp` = Temps dâ€™exÃ©cution en **parallÃ¨le**, avec `p` processeurs
- `Sp` = le **gain de vitesse**

### 

un exemple 

| Version             | Temps       |
| ------------------- | ----------- |
| SÃ©quentiel          | 10 secondes |
| ParallÃ¨le (4 cÅ“urs) | 3 secondes  |

Alors :

```cpp
Sp = 10 / 3 â‰ˆ 3.33
```

â¡ï¸ Tu vas 3,33 fois plus vite avec 4 cÅ“urs ! ğŸ’ª



ğŸ§  3. Lâ€™idÃ©al thÃ©orique

> Si ton code est **parfaitement parallÃ©lisable**, alors :

```
Sp â‰ˆ p
```

ğŸ“Œ Exemple : 4 cÅ“urs â‡’ on pourrait espÃ©rer **4 fois plus rapide**.

Mais... ğŸ˜¢ dans la vraie vie, **tout ne peut pas Ãªtre parallÃ©lisÃ©**. Et câ€™est lÃ  quâ€™intervientâ€¦



ğŸ“ 4. La **loi dâ€™Amdahl** (âš ï¸ super importante)



Elle dit :

```cpp
Speedup â‰¤ 1 / ((1 - S) + S / P)
```

`S` : pourcentage de ton code **parallÃ©lisable** (entre 0 et 1)

`P` : nombre de processeurs (ou threads/cÅ“urs)

`1 - S` : partie du code qui **reste sÃ©quentielle**



ğŸ“Œ Exemple : 90 % parallÃ©lisable (`S = 0.9`)



| Nombre de cÅ“urs `P` | Calcul du speedup                 | RÃ©sultat   |
| ------------------- | --------------------------------- | ---------- |
| 1                   | `1 / ((1 - 0.9) + 0.9/1) = 1`     | 1 (normal) |
| 2                   | `1 / (0.1 + 0.9/2) = 1 / 0.55`    | â‰ˆ 1.82     |
| 4                   | `1 / (0.1 + 0.9/4) = 1 / 0.325`   | â‰ˆ 3.08     |
| 100                 | `1 / (0.1 + 0.9/100) = 1 / 0.109` | â‰ˆ 9.17     |

â¡ï¸ MÃªme avec **100 processeurs**, tu ne dÃ©passes pas **9,17x plus vite** â—

Pourquoi ? Parce que les **10 % restants** te **freinent** toujours !



### ğŸ’¡ Exemple

Si 90 % de ton code est parallÃ©lisable (`S = 0.9`) :

- avec 4 processeurs â†’ speedup max â‰ˆ 3.08
- avec 100 processeurs â†’ speedup max â‰ˆ 9.17

On voit que **ajouter plus de processeurs** nâ€™aide plus passÃ© un certain point âš ï¸

